{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pSDsePTyLzkZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maraboux/kuda_template/blob/main/Agency_Swarm_Quick_Start.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sSR2RQa0Z3V3",
        "outputId": "0d30f433-ddba-4f91-fa12-14cf916d4976",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting agency-swarm\n",
            "  Downloading agency_swarm-0.2.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.41.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-6.2.6-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting openai==1.35.14 (from agency-swarm)\n",
            "  Downloading openai-1.35.14-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting instructor==1.3.4 (from agency-swarm)\n",
            "  Downloading instructor-1.3.4-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting datamodel-code-generator==0.25.8 (from agency-swarm)\n",
            "  Downloading datamodel_code_generator-0.25.8-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting deepdiff==6.7.1 (from agency-swarm)\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: termcolor==2.4.0 in /usr/local/lib/python3.10/dist-packages (from agency-swarm) (2.4.0)\n",
            "Collecting python-dotenv==1.0.1 (from agency-swarm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: rich==13.7.1 in /usr/local/lib/python3.10/dist-packages (from agency-swarm) (13.7.1)\n",
            "Collecting jsonref==1.1.0 (from agency-swarm)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting argcomplete<4.0,>=1.10 (from datamodel-code-generator==0.25.8->agency-swarm)\n",
            "  Downloading argcomplete-3.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting black>=19.10b0 (from datamodel-code-generator==0.25.8->agency-swarm)\n",
            "  Downloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting genson<2.0,>=1.2.1 (from datamodel-code-generator==0.25.8->agency-swarm)\n",
            "  Downloading genson-1.3.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting inflect<6.0,>=4.1.0 (from datamodel-code-generator==0.25.8->agency-swarm)\n",
            "  Downloading inflect-5.6.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting isort<6.0,>=4.3.21 (from datamodel-code-generator==0.25.8->agency-swarm)\n",
            "  Downloading isort-5.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: jinja2<4.0,>=2.10.1 in /usr/local/lib/python3.10/dist-packages (from datamodel-code-generator==0.25.8->agency-swarm) (3.1.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datamodel-code-generator==0.25.8->agency-swarm) (24.1)\n",
            "Requirement already satisfied: pydantic!=2.4.0,<3.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from pydantic[email]!=2.4.0,<3.0,>=1.9.0; python_version >= \"3.10\" and python_version < \"3.11\"->datamodel-code-generator==0.25.8->agency-swarm) (2.8.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from datamodel-code-generator==0.25.8->agency-swarm) (6.0.1)\n",
            "Requirement already satisfied: toml<1.0.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from datamodel-code-generator==0.25.8->agency-swarm) (0.10.2)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff==6.7.1->agency-swarm)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from instructor==1.3.4->agency-swarm) (3.10.1)\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor==1.3.4->agency-swarm) (0.16)\n",
            "Collecting jiter<0.5.0,>=0.4.1 (from instructor==1.3.4->agency-swarm)\n",
            "  Downloading jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor==1.3.4->agency-swarm) (2.20.1)\n",
            "Collecting tenacity<9.0.0,>=8.2.3 (from instructor==1.3.4->agency-swarm)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from instructor==1.3.4->agency-swarm) (0.12.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.35.14->agency-swarm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.35.14->agency-swarm) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.35.14->agency-swarm)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.35.14->agency-swarm) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.35.14->agency-swarm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.35.14->agency-swarm) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.1->agency-swarm) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich==13.7.1->agency-swarm) (2.16.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.112.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting primp>=0.5.5 (from duckduckgo-search)\n",
            "  Downloading primp-0.5.5-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.35.14->agency-swarm) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.35.14->agency-swarm) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.35.14->agency-swarm) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.35.14->agency-swarm)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.35.14->agency-swarm)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.4.0,<3.0,>=1.9.0->pydantic[email]!=2.4.0,<3.0,>=1.9.0; python_version >= \"3.10\" and python_version < \"3.11\"->datamodel-code-generator==0.25.8->agency-swarm) (0.7.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.9.0->instructor==1.3.4->agency-swarm) (1.5.4)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.4->agency-swarm) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.4->agency-swarm) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.4->agency-swarm) (24.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.4->agency-swarm) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.4->agency-swarm) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.4->agency-swarm) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.3.4->agency-swarm) (4.0.3)\n",
            "Collecting mypy-extensions>=0.4.3 (from black>=19.10b0->datamodel-code-generator==0.25.8->agency-swarm)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black>=19.10b0->datamodel-code-generator==0.25.8->agency-swarm)\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black>=19.10b0->datamodel-code-generator==0.25.8->agency-swarm) (4.2.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black>=19.10b0->datamodel-code-generator==0.25.8->agency-swarm) (2.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich==13.7.1->agency-swarm) (0.1.2)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]!=2.4.0,<3.0,>=1.9.0; python_version >= \"3.10\" and python_version < \"3.11\"->datamodel-code-generator==0.25.8->agency-swarm)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]!=2.4.0,<3.0,>=1.9.0; python_version >= \"3.10\" and python_version < \"3.11\"->datamodel-code-generator==0.25.8->agency-swarm)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading agency_swarm-0.2.6-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datamodel_code_generator-0.25.8-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.3.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading openai-1.35.14-py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading gradio-4.41.0-py3-none-any.whl (12.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.6/12.6 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading duckduckgo_search-6.2.6-py3-none-any.whl (27 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primp-0.5.5-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.5.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.5-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading argcomplete-3.5.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading black-24.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading genson-1.3.0-py3-none-any.whl (21 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflect-5.6.2-py3-none-any.whl (33 kB)\n",
            "Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (327 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.6/327.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, genson, websockets, tomlkit, tenacity, semantic-version, ruff, python-multipart, python-dotenv, primp, pathspec, orjson, ordered-set, mypy-extensions, jsonref, jiter, isort, inflect, h11, ffmpy, dnspython, argcomplete, aiofiles, uvicorn, starlette, httpcore, email-validator, duckduckgo-search, deepdiff, black, httpx, fastapi, openai, gradio-client, datamodel-code-generator, instructor, gradio, agency-swarm\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.0\n",
            "    Uninstalling tomlkit-0.13.0:\n",
            "      Successfully uninstalled tomlkit-0.13.0\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: inflect\n",
            "    Found existing installation: inflect 7.3.1\n",
            "    Uninstalling inflect-7.3.1:\n",
            "      Successfully uninstalled inflect-7.3.1\n",
            "Successfully installed agency-swarm-0.2.6 aiofiles-23.2.1 argcomplete-3.5.0 black-24.8.0 datamodel-code-generator-0.25.8 deepdiff-6.7.1 dnspython-2.6.1 duckduckgo-search-6.2.6 email-validator-2.2.0 fastapi-0.112.0 ffmpy-0.4.0 genson-1.3.0 gradio-4.41.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 inflect-5.6.2 instructor-1.3.4 isort-5.13.2 jiter-0.4.2 jsonref-1.1.0 mypy-extensions-1.0.0 openai-1.35.14 ordered-set-4.1.0 orjson-3.10.7 pathspec-0.12.1 primp-0.5.5 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.5.7 semantic-version-2.10.0 starlette-0.37.2 tenacity-8.5.0 tomlkit-0.12.0 uvicorn-0.30.5 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install agency-swarm gradio duckduckgo-search"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import set_openai_key\n",
        "from getpass import getpass\n",
        "set_openai_key(getpass(\"Please enter your openai key: \"))"
      ],
      "metadata": {
        "id": "dHqVhxU-x1rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 1: Use Genesis Agency\n",
        "\n",
        "Genesis agency is a special pre-made agency that will create all your agents for you. All you have to do is send your requirements, mission, apis that you want to connect to. Your agent files will appear under files on the left.\n",
        "\n",
        "### Creating Agents\n",
        "\n",
        "To test this, simply run the cell below and click on the URL. Then, send your agency description. For example:\n",
        "\n",
        "> Please create a social media marketing agency with 3 agents that connects to facebook api\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PAuJDvpOKQqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm.agency.genesis import GenesisAgency\n",
        "\n",
        "agency = GenesisAgency(with_browsing=False)\n",
        "\n",
        "demo = agency.demo_gradio(height=900)\n",
        "\n",
        "# example task:\n",
        "# Please create a social media marketing agency with 3 agents that connects to facebook api"
      ],
      "metadata": {
        "id": "nodGJXp7Krmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running Your New Agency\n",
        "\n",
        "All your agent files will appear in `files` on the left. You can then copy them to your local PC and continue working, or modify them directly in Google Collab.\n",
        "\n",
        "To run your new agency, simply replace `<YOUR_AGENCY_NAME>` with the name of your agency folder on the left and run the cell below."
      ],
      "metadata": {
        "id": "2Ckrh7jhKrTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from SocialMediaMasters.agency import agency\n",
        "from <YOUR_AGENCY_NAME>.agency import agency\n",
        "\n",
        "if demo:\n",
        "  demo.close()\n",
        "\n",
        "demo = agency.demo_gradio(height=900)"
      ],
      "metadata": {
        "id": "yZ5AcEZ8MEA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Option 2: Create Agents From Scratch."
      ],
      "metadata": {
        "id": "OZV8BiryKhsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CEO Agent\n"
      ],
      "metadata": {
        "id": "1h43Eh0PSDHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ceo_instructions = \"\"\"# Instructions for CEO Agent\n",
        "\n",
        "- Ensure that proposal is send to the user before proceeding with task execution.\n",
        "- Delegate tasks to appropriate agents, ensuring they align with their expertise and capabilities.\n",
        "- Clearly define the objectives and expected outcomes for each task.\n",
        "- Provide necessary context and background information for successful task completion.\n",
        "- Maintain ongoing communication with agents until complete task execution.\n",
        "- Review completed tasks to ensure they meet the set objectives.\n",
        "- Report the results back to the user.\"\"\""
      ],
      "metadata": {
        "id": "w7xwtx3-LWna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import Agent\n",
        "\n",
        "ceo = Agent(name=\"CEO\",\n",
        "            description=\"Responsible for client communication, task planning and management.\",\n",
        "            instructions=ceo_instructions, # can be a file like ./instructions.md\n",
        "            files_folder=None,\n",
        "            tools=[])"
      ],
      "metadata": {
        "id": "NKFbvF54SGT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Virtual Assistant"
      ],
      "metadata": {
        "id": "y_9zs8XLrkal"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing tools from langchain example.  \n",
        "You can skip these and remove them from va agent below."
      ],
      "metadata": {
        "id": "pSDsePTyLzkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "|!pip install langchain==0.0.318 &> /dev/null"
      ],
      "metadata": {
        "id": "sY8FY_UwLKy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utilities.zapier import ZapierNLAWrapper\n",
        "from langchain.agents.agent_toolkits import ZapierToolkit\n",
        "import os\n",
        "from langchain.tools import format_tool_to_openai_function\n",
        "from langchain.tools.zapier.tool import ZapierNLARunAction\n",
        "\n",
        "# https://nla.zapier.com/docs/authentication/\n",
        "os.environ[\"ZAPIER_NLA_API_KEY\"] = getpass(\"Your Zapier NLA Key: \")"
      ],
      "metadata": {
        "id": "zE7zTpfILy5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import BaseTool\n",
        "from pydantic import Field\n",
        "\n",
        "actions = ZapierNLAWrapper().list()\n",
        "\n",
        "class FindEmail(BaseTool):\n",
        "    \"\"\"Use this tool to find an email in user's mailbox\"\"\"\n",
        "    instructions: str = Field(..., description=\"The search phrase you want to use to find a relevant email.\")\n",
        "\n",
        "    def run(self):\n",
        "      action = next(\n",
        "          (a for a in actions if a[\"description\"].startswith(\"Gmail: Find Email\")), None\n",
        "      )\n",
        "      return str(ZapierNLARunAction(\n",
        "              action_id=action[\"id\"],\n",
        "              zapier_description=action[\"description\"],\n",
        "              params_schema=action[\"params\"],\n",
        "          ).run(self.search_string))\n",
        "\n",
        "class DraftEmail(BaseTool):\n",
        "    \"\"\"Use this tool to draft a response email\"\"\"\n",
        "    instructions: str = Field(..., description=\"Clearly outline in natural language the content of the email you need to draft and the address of the recepient.\")\n",
        "\n",
        "    def run(self):\n",
        "        action = next(\n",
        "            (a for a in actions if a[\"description\"].startswith(\"Gmail: Create Draft Reply\")), None\n",
        "        )\n",
        "        return str(ZapierNLARunAction(\n",
        "                action_id=action[\"id\"],\n",
        "                zapier_description=action[\"description\"],\n",
        "                params_schema=action[\"params\"],\n",
        "            ).run(self.instructions))"
      ],
      "metadata": {
        "id": "w2OO-KxEuh8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom tools with [Instructor](https://github.com/jxnl/instructor)"
      ],
      "metadata": {
        "id": "B5m14T_KhwFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from duckduckgo_search import DDGS\n",
        "from agency_swarm.util.oai import get_openai_client\n",
        "\n",
        "client = get_openai_client()\n",
        "\n",
        "\n",
        "class SearchWeb(BaseTool):\n",
        "    \"\"\"Search the web with a search phrase and return the results.\"\"\"\n",
        "\n",
        "    phrase: str = Field(..., description=\"The search phrase you want to use. Optimize the search phrase for an internet search engine.\")\n",
        "\n",
        "    # This code will be executed if the agent calls this tool\n",
        "    def run(self):\n",
        "      with DDGS() as ddgs:\n",
        "        return str([r for r in ddgs.text(self.phrase, max_results=3)])\n",
        "\n",
        "class GenerateProposal(BaseTool):\n",
        "    \"\"\"Generate a proposal for a project based on a project brief. Remember that user does not have access to the output of this function. You must send it back to him after execution.\"\"\"\n",
        "    project_brief: str = Field(..., description=\"The project breif to generate a proposal for.\")\n",
        "\n",
        "    def run(self):\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "              {\"role\": \"system\", \"content\": \"You are a professional proposal drafting assistant. Do not include any actual technologies or technical details into proposal until specified in the project brief. Be short.\"},\n",
        "              {\"role\": \"user\", \"content\": \"Please draft a proposal for the ollowing project brief: \" + self.project_brief}\n",
        "            ]\n",
        "          )\n",
        "\n",
        "        return str(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "MxkO2GHnNekC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "va_instructions = \"\"\"### Instructions for Virtual Assistant\n",
        "\n",
        "Your role is to assist users in executing tasks like below. If the task is outside of your capabilities, please report back to the user.\n",
        "\n",
        "#### 1. Drafting Emails\n",
        "   - **Understand Context and Tone**: Familiarize yourself with the context of each email. Maintain a professional and courteous tone.\n",
        "   - **Accuracy and Clarity**: Ensure that the information is accurate and presented clearly. Avoid jargon unless it's appropriate for the recipient.\n",
        "\n",
        "#### 2. Generating Proposals\n",
        "   - **Gather Requirements**: Collect all necessary information about the project, including client needs, objectives, and any specific requests.\n",
        "\n",
        "#### 3. Conducting Research\n",
        "   - **Understand the Objective**: Clarify the purpose and objectives of the research to focus on relevant information.\n",
        "   - **Summarize Findings**: Provide clear, concise summaries of the research findings, highlighting key points and how they relate to the project or inquiry.\n",
        "   - **Cite Sources**: Properly cite all sources to maintain integrity and avoid plagiarism.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8u4x6gdeSARg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "va = Agent(name=\"Virtual Assistant\",\n",
        "            description=\"Responsible for drafting emails, doing research and writing proposals.\",\n",
        "            instructions=va_instructions,\n",
        "            files_folder=None,\n",
        "            tools=[SearchWeb, FindEmail, DraftEmail, GenerateProposal])"
      ],
      "metadata": {
        "id": "6e8aWSRRBlBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Developer Agent"
      ],
      "metadata": {
        "id": "x0zLIv1i75gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm.tools import BaseTool\n",
        "from pydantic import Field, BaseModel\n",
        "import subprocess\n",
        "from typing import List\n",
        "\n",
        "\n",
        "class ExecuteCommand(BaseTool):\n",
        "    \"\"\"Run any command from the terminal. If there are too many logs, the outputs might be truncated.\"\"\"\n",
        "    command: str = Field(\n",
        "        ..., description=\"The command to be executed.\"\n",
        "    )\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Executes the given command and captures its output and errors.\"\"\"\n",
        "        try:\n",
        "            # Splitting the command into a list of arguments\n",
        "            command_args = self.command.split()\n",
        "\n",
        "            # Executing the command\n",
        "            result = subprocess.run(\n",
        "                command_args,\n",
        "                text=True,\n",
        "                capture_output=True,\n",
        "                check=True\n",
        "            )\n",
        "            return result.stdout\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            return f\"An error occurred: {e.stderr}\"\n",
        "\n",
        "class File(BaseTool):\n",
        "    \"\"\"\n",
        "    File to be written to the disk with an appropriate name and file path, containing code that can be saved and executed locally at a later time.\n",
        "    \"\"\"\n",
        "    file_name: str = Field(\n",
        "        ..., description=\"The name of the file including the extension and the file path from your current directory if needed.\"\n",
        "    )\n",
        "    body: str = Field(..., description=\"Correct contents of a file\")\n",
        "\n",
        "    def run(self):\n",
        "        # Extract the directory path from the file name\n",
        "        directory = os.path.dirname(self.file_name)\n",
        "\n",
        "        # If the directory is not empty, check if it exists and create it if not\n",
        "        if directory and not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "        # Write the file\n",
        "        with open(self.file_name, \"w\") as f:\n",
        "            f.write(self.body)\n",
        "\n",
        "        return \"File written to \" + self.file_name\n",
        "\n",
        "class Program(BaseTool):\n",
        "    \"\"\"\n",
        "    Set of files that represent a complete and correct program. This environment has access to all standard Python packages and the internet.\n",
        "    \"\"\"\n",
        "    chain_of_thought: str = Field(...,\n",
        "        description=\"Think step by step to determine the correct actions that are needed to implement the program.\")\n",
        "    files: List[File] = Field(..., description=\"List of files\")\n",
        "\n",
        "    def run(self):\n",
        "      outputs = []\n",
        "      for file in self.files:\n",
        "        outputs.append(file.run())\n",
        "\n",
        "      return str(outputs)"
      ],
      "metadata": {
        "id": "aIhhoDWx8BZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_instructions = \"\"\"# Instructions for AI Developer Agent\n",
        "\n",
        "- Write clean and efficient Python code.\n",
        "- Structure your code logically, with `main.py` as the entry point.\n",
        "- Ensure correct imports according to program structure.\n",
        "- Execute your code to test for functionality and errors, before reporting back to the user.\n",
        "- Anticipate and handle potential runtime errors.\n",
        "- Provide clear error messages for easier troubleshooting.\n",
        "- Debug any issues before reporting the results back to the user.\"\"\""
      ],
      "metadata": {
        "id": "lStK381cVF7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm.tools import Retrieval, CodeInterpreter\n",
        "\n",
        "dev = Agent(name=\"Developer\",\n",
        "            description=\"Responsible for running and executing Python Programs.\",\n",
        "            instructions=dev_instructions,\n",
        "            files_folder=None,\n",
        "            tools=[ExecuteCommand, Program])\n"
      ],
      "metadata": {
        "id": "7nAlYUHd74pX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Agency\n",
        "\n",
        "`shared_instructions` will be shared accross all agents."
      ],
      "metadata": {
        "id": "8kXMaOqSSb_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agency_manifesto = \"\"\"# \"VRSEN AI\" Agency Manifesto\n",
        "\n",
        "You are a part of a virtual AI development agency called \"VRSEN AI\"\n",
        "\n",
        "Your mission is to empower businesses to navigate the AI revolution successfully.\"\"\""
      ],
      "metadata": {
        "id": "7rer151XX8Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from agency_swarm import Agency\n",
        "\n",
        "agency = Agency([\n",
        "    ceo,\n",
        "    [ceo, dev],\n",
        "    [ceo, va],\n",
        "    [dev, va]\n",
        "], shared_instructions=agency_manifesto)"
      ],
      "metadata": {
        "id": "mr2apzHySegB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Demo"
      ],
      "metadata": {
        "id": "I2CHn1B7ShEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agency.demo_gradio(height=900)"
      ],
      "metadata": {
        "id": "vpGRiEeulQZv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}